{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/lehuong240823/rag-company-knowledge-consultant-chatbot/blob/main/ChatBot.ipynb",
      "authorship_tag": "ABX9TyOSB/MJCQ1wzdEbVNXJHZ/j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lehuong240823/rag-company-knowledge-consultant-chatbot/blob/main/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Started"
      ],
      "metadata": {
        "id": "20GrbDZgi1mj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QJQ8OZPL5war",
        "collapsed": true,
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5acce9b7-13c9-4b71-d91d-7fb78b6a41eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/587.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m501.8/587.6 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m583.7/587.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.6/587.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.3/259.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# @title Install Libraries\n",
        "!pip -q install pinecone\n",
        "!pip -q install langchain_community\n",
        "!pip -q install langchain_openai\n",
        "!pip -q install langchain_pinecone\n",
        "!pip -q install langchain-huggingface\n",
        "!pip -q install langsmith"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Import Libraries\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEndpointEmbeddings\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from pinecone import Pinecone, ServerlessSpec"
      ],
      "metadata": {
        "id": "nRwdJs_82XKX",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86bab7a9-ff1f-4d22-cecd-14282073eeda"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/langchain_pinecone/__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Set Environment Variables\n",
        "os.environ['PINECONE_API_KEY'] = userdata.get('PINECONE_API_KEY')\n",
        "os.environ['PINECONE_INDEX_NAME'] = 'langchain-test-index'\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENROUTER_API_KEY')\n",
        "os.environ['OPENAI_API_BASE'] = 'https://openrouter.ai/api/v1'\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = userdata.get('HF_TOKEN')\n",
        "os.environ['PINECONE_INDEX_NAME'] = userdata.get('PINECONE_INDEX_NAME')\n",
        "os.environ['LANGSMITH_TRACING'] = 'true'\n",
        "os.environ['LANGSMITH_API_KEY'] = userdata.get('LANGSMITH_API_KEY')"
      ],
      "metadata": {
        "id": "_SC-bUdQ15Aq",
        "cellView": "form"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method"
      ],
      "metadata": {
        "id": "tJUrQT_gZ5Z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Get Pinecone Index\n",
        "def get_index(index_name=os.environ['PINECONE_INDEX_NAME']):\n",
        "  pc = Pinecone()\n",
        "  if not pc.has_index(index_name):\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=4096,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(\n",
        "            cloud='aws',\n",
        "            region='us-east-1'\n",
        "        )\n",
        "    )\n",
        "\n",
        "  return pc.Index(index_name)"
      ],
      "metadata": {
        "id": "EwutUmxfMdsj",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Text Splitter\n",
        "def init_text_splitter(chunk_size=1000, chunk_overlap=0):\n",
        "  return CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)"
      ],
      "metadata": {
        "id": "EraOySvvAa4p",
        "cellView": "form"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Add Documents to Vector Store\n",
        "def add_documents(path):\n",
        "  loader = TextLoader(path)\n",
        "  documents = loader.load()\n",
        "  print(f\"Loaded {len(documents)} document(s) from {path}\")\n",
        "  docs = text_splitter.split_documents(documents)\n",
        "  vectorstore.add_documents(docs)\n",
        "  print(f\"Added {len(docs)} text chunk(s) to vector store.\")"
      ],
      "metadata": {
        "id": "WTe9PQ6I8fV4",
        "cellView": "form"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Add Texts to Vector Store\n",
        "def add_texts(text):\n",
        "  texts = text_splitter.split_text(text)\n",
        "  vectorstore.add_texts(texts)\n",
        "  print(f\"Added {len(texts)} text chunks to vector store.\")"
      ],
      "metadata": {
        "id": "EU2XDErYCfLH",
        "cellView": "form"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Initialize Components\n",
        "\n",
        "index = get_index()\n",
        "\n",
        "llm = ChatOpenAI(model='qwen/qwen3-8b:free')\n",
        "\n",
        "embeddings = HuggingFaceEndpointEmbeddings(model='Qwen/Qwen3-Embedding-8B')\n",
        "\n",
        "vectorstore = PineconeVectorStore(index=index, embedding=embeddings)\n",
        "\n",
        "text_splitter = init_text_splitter()\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=vectorstore.as_retriever(),\n",
        "    return_source_documents=True\n",
        ")"
      ],
      "metadata": {
        "id": "KCuTVFQOp-z_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluator"
      ],
      "metadata": {
        "id": "275hVmB1dD74"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9fc54bb",
        "outputId": "3c82a3f0-38ce-4a3e-ba44-67b270b47689"
      },
      "source": [
        "query = \"công ty này ở phường nào\"\n",
        "response = qa_chain.invoke({\"query\": query})\n",
        "\n",
        "print(response)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'công ty này ở phường nào', 'result': 'Tôi không biết công ty cụ thể bạn đang hỏi là công ty nào. Bạn có thể cho biết tên công ty hoặc thêm thông tin liên quan đến địa chỉ của nó được không? Tôi sẽ giúp bạn tìm kiếm thông tin chính xác hơn.', 'source_documents': []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "dataset_path = userdata.get('DATASET_PATH')"
      ],
      "metadata": {
        "id": "KOuHSiwe9uZ_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()\n",
        "\n",
        "examples = json.load(open(dataset_path))\n",
        "\n",
        "dataset_name = \"FQ&A\"\n",
        "dataset = client.create_dataset(dataset_name='FQA')\n",
        "client.create_examples(\n",
        "    dataset_id=dataset.id,\n",
        "    examples=examples\n",
        ")\n"
      ],
      "metadata": {
        "id": "U-1Y-AuQjRNl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b26bab05-eb49-447c-a055-df987fd310d0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'example_ids': ['e81bee28-69f5-4c43-8c95-7b2f1474e93b',\n",
              "  'd012d491-07a0-4cfb-9ac8-d95aeb785176',\n",
              "  'bf8463d8-79f1-401a-bc8b-716bda9ceaf8'],\n",
              " 'count': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}