{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1wGpqLbAiYNu4crXU4qPeTfCmND3TBEdl",
      "authorship_tag": "ABX9TyNZ/drfYMuxDE1fsPwR9rY9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lehuong240823/rag-company-knowledge-consultant-chatbot/blob/main/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Started"
      ],
      "metadata": {
        "id": "20GrbDZgi1mj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJQ8OZPL5war",
        "collapsed": true,
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "134d559e-6025-414f-8992-07a6c1d7dbd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/587.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m583.7/587.6 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.6/587.6 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/259.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.3/259.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.0/444.0 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.2/52.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.2/221.2 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# @title Install Libraries\n",
        "!pip -q install pinecone\n",
        "!pip -q install langchain_community\n",
        "!pip -q install langchain_openai\n",
        "!pip -q install langchain_pinecone\n",
        "!pip -q install langchain-huggingface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Import Libraries\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEndpointEmbeddings\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "from pinecone import Pinecone, ServerlessSpec"
      ],
      "metadata": {
        "id": "nRwdJs_82XKX",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Set Environment Variables\n",
        "os.environ['PINECONE_API_KEY'] = userdata.get('PINECONE_API_KEY')\n",
        "os.environ['PINECONE_INDEX_NAME'] = 'langchain-test-index'\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENROUTER_API_KEY')\n",
        "os.environ['OPENAI_API_BASE'] = 'https://openrouter.ai/api/v1'\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = userdata.get('HF_TOKEN')\n",
        "os.environ['PINECONE_INDEX_NAME'] = userdata.get('PINECONE_INDEX_NAME')"
      ],
      "metadata": {
        "id": "_SC-bUdQ15Aq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method"
      ],
      "metadata": {
        "id": "tJUrQT_gZ5Z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Get Pinecone Index\n",
        "def get_index(index_name=os.environ['PINECONE_INDEX_NAME']):\n",
        "  pc = Pinecone()\n",
        "  if not pc.has_index(index_name):\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=4096,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(\n",
        "            cloud='aws',\n",
        "            region='us-east-1'\n",
        "        )\n",
        "    )\n",
        "\n",
        "  return pc.Index(index_name)"
      ],
      "metadata": {
        "id": "EwutUmxfMdsj",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Text Splitter\n",
        "def init_text_splitter(chunk_size=1000, chunk_overlap=0):\n",
        "  return CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)"
      ],
      "metadata": {
        "id": "EraOySvvAa4p",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Add Documents to Vector Store\n",
        "def add_documents(path):\n",
        "  loader = TextLoader(path)\n",
        "  documents = loader.load()\n",
        "  print(f\"Loaded {len(documents)} document(s) from {path}\")\n",
        "  docs = text_splitter.split_documents(documents)\n",
        "  vectorstore.add_documents(docs)\n",
        "  print(f\"Added {len(docs)} text chunk(s) to vector store.\")"
      ],
      "metadata": {
        "id": "WTe9PQ6I8fV4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Add Texts to Vector Store\n",
        "def add_texts(text):\n",
        "  texts = text_splitter.split_text(text)\n",
        "  vectorstore.add_texts(texts)\n",
        "  print(f\"Added {len(texts)} text chunks to vector store.\")"
      ],
      "metadata": {
        "id": "EU2XDErYCfLH",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Initialize Components\n",
        "\n",
        "index = get_index()\n",
        "\n",
        "llm = ChatOpenAI(model='qwen/qwen3-8b:free')\n",
        "\n",
        "embeddings = HuggingFaceEndpointEmbeddings(model='Qwen/Qwen3-Embedding-8B')\n",
        "\n",
        "vectorstore = PineconeVectorStore(index=index, embedding=embeddings)\n",
        "\n",
        "text_splitter = init_text_splitter()\n",
        "\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm,\n",
        "    retriever=vectorstore.as_retriever(),\n",
        "    return_source_documents=True\n",
        ")"
      ],
      "metadata": {
        "id": "KCuTVFQOp-z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "275hVmB1dD74"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9fc54bb",
        "outputId": "3c82a3f0-38ce-4a3e-ba44-67b270b47689"
      },
      "source": [
        "\n",
        "query = \"công ty này ở phường nào\"\n",
        "response = qa_chain.invoke({\"query\": query})\n",
        "\n",
        "print(response)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': 'công ty này ở phường nào', 'result': 'Tôi không biết công ty cụ thể bạn đang hỏi là công ty nào. Bạn có thể cho biết tên công ty hoặc thêm thông tin liên quan đến địa chỉ của nó được không? Tôi sẽ giúp bạn tìm kiếm thông tin chính xác hơn.', 'source_documents': []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3GVUCO8rixVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U-1Y-AuQjRNl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}