{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lehuong240823/rag-company-knowledge-consultant-chatbot/blob/main/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20GrbDZgi1mj"
      },
      "source": [
        "# Get Started"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "collapsed": true,
        "id": "QJQ8OZPL5war"
      },
      "outputs": [],
      "source": [
        "# @title Install Libraries\n",
        "!pip -q install pinecone\n",
        "!pip -q install langchain_community\n",
        "!pip -q install langchain_openai\n",
        "!pip -q install langchain_pinecone\n",
        "!pip -q install langchain-huggingface\n",
        "!pip -q install langsmith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "cellView": "form",
        "id": "nRwdJs_82XKX"
      },
      "outputs": [],
      "source": [
        "# @title Import Libraries\n",
        "import os, yaml, inspect, json\n",
        "from os.path import join\n",
        "from google.colab import userdata\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEndpointEmbeddings\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
        "from langchain_pinecone.vectorstores import PineconeVectorStore\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from langsmith import Client, traceable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "_SC-bUdQ15Aq"
      },
      "outputs": [],
      "source": [
        "# @title Set Environment Variables\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = userdata.get('HF_TOKEN')\n",
        "os.environ['LANGSMITH_API_KEY'] = userdata.get('LANGSMITH_API_KEY')\n",
        "os.environ['LANGSMITH_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGSMITH_PROJECT'] = userdata.get('PINECONE_INDEX_NAME')\n",
        "os.environ['LANGSMITH_TRACING'] = 'true'\n",
        "os.environ['OPENAI_API_BASE'] = 'https://router.huggingface.co/v1' #'https://openrouter.ai/api/v1'\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('HF_TOKEN') #userdata.get('OPENROUTER_API_KEY')\n",
        "os.environ['PINECONE_API_KEY'] = userdata.get('PINECONE_API_KEY')\n",
        "os.environ['PINECONE_INDEX_NAME'] = userdata.get('PINECONE_INDEX_NAME')\n",
        "root_path =  userdata.get('ROOT_PATH')\n",
        "embedding_path = join(root_path, 'embedding_data')\n",
        "reference_path = join(root_path, 'reference_data')\n",
        "evaluators_path = join(root_path, 'evaluators_path')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJUrQT_gZ5Z3"
      },
      "source": [
        "# Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EwutUmxfMdsj"
      },
      "outputs": [],
      "source": [
        "# @title Get Pinecone Index\n",
        "def get_index(index_name=os.environ['PINECONE_INDEX_NAME']):\n",
        "  pc = Pinecone()\n",
        "  if not pc.has_index(index_name):\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=4096,\n",
        "        metric='cosine',\n",
        "        spec=ServerlessSpec(\n",
        "            cloud='aws',\n",
        "            region='us-east-1'\n",
        "        )\n",
        "    )\n",
        "\n",
        "  return pc.Index(index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EraOySvvAa4p"
      },
      "outputs": [],
      "source": [
        "# @title Create Text Splitter\n",
        "def create_text_splitter(chunk_size=1000, chunk_overlap=0):\n",
        "  return CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "id": "WTe9PQ6I8fV4"
      },
      "outputs": [],
      "source": [
        "# @title Add Documents to Vector Store\n",
        "def Loader(file):\n",
        "  if file.endswith('.csv'):\n",
        "    loader = CSVLoader(file)\n",
        "  elif file.endswith('.txt'):\n",
        "    loader = TextLoader(file)\n",
        "  return loader\n",
        "\n",
        "def add_documents(path, ids):\n",
        "  loader = Loader(path)\n",
        "  documents = loader.load()\n",
        "  print(f'Loaded {len(documents)} document(s) from {path}')\n",
        "  docs = text_splitter.split_documents(documents)\n",
        "  print(docs)\n",
        "  #print([f'{ids}_{str(i)}' for i in range(0, len(docs))])\n",
        "  #vectorstore.add_documents(docs, ids=[\"doc1\", \"doc2\"])\n",
        "  print(f'Added {len(docs)} text chunk(s) to vector store.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = Loader('https://github.com/lehuong240823/rag-company-knowledge-consultant-chatbot/landing_doanh_nghiep.txt')\n",
        "documents = loader.load()\n",
        "print(documents)"
      ],
      "metadata": {
        "id": "20U7AuiJ4AFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for root, dirs, files in os.walk(reference_path):\n",
        "  for name in files:\n",
        "    #add_documents(join(root, name))\n",
        "    path = join(root, name)\n",
        "    add_documents(path, name[:-4])\n",
        "\n"
      ],
      "metadata": {
        "id": "2zkQi2ymS42J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EU2XDErYCfLH"
      },
      "outputs": [],
      "source": [
        "# @title Add Texts to Vector Store\n",
        "def add_texts(text):\n",
        "  texts = text_splitter.split_text(text)\n",
        "  vectorstore.add_texts(texts)\n",
        "  print(f'Added {len(texts)} text chunks to vector store.')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "eba05b0e"
      },
      "source": [
        "# @title Get Evaluator Path\n",
        "def get_evaluator_path(evaluator_name):\n",
        "  return f'{evaluators_path}/{evaluator_name}'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "fdc50271"
      },
      "source": [
        "# @title Load Output Schema\n",
        "def load_output_schema(evaluator_name):\n",
        "  file_path = f'{get_evaluator_path(evaluator_name)}/output_schema.yaml'\n",
        "  with open(file_path, 'r') as f:\n",
        "    return yaml.safe_load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc4dc6ba"
      },
      "source": [
        "# @title Load Chat Prompt\n",
        "def load_chat_prompt(evaluator):\n",
        "  file_path = f'{get_evaluator_path(evaluator)}/prompt.yaml'\n",
        "  with open(file_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "  role_map = {'system': SystemMessagePromptTemplate, 'user': HumanMessagePromptTemplate, 'ai': AIMessagePromptTemplate}\n",
        "\n",
        "  messages = []\n",
        "  for msg_config in config['messages']:\n",
        "    messages.append(role_map[msg_config['role']].from_template(msg_config['template']))\n",
        "  #messages = [role_map[m['role']].from_template(m['template']) for m in cfg['messages']]\n",
        "\n",
        "  return ChatPromptTemplate.from_messages(messages)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Create LangSmith Dataset\n",
        "def create_dataset(file_name, dataset_name=None, provider='langsmith'):\n",
        "  #Load json file only\n",
        "  dataset_name = file_name[:-5] if dataset_name is None else dataset_name\n",
        "  with open(join(embedding_path, provider, file_name)) as f:\n",
        "    if not client.has_dataset(dataset_name=dataset_name):\n",
        "      return client.create_dataset(dataset_name=dataset_name)\n",
        "      client.create_examples(\n",
        "        dataset_id=dataset.id,\n",
        "        examples=json.load(f)\n",
        "      )"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SBX_Qx0pMcuq"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMr6Xf8SnsEt",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Create Structured Grader LLM\n",
        "def create_structured_grader_llm(model='qwen/qwen3-8b:free', temperature=0, evaluator=None):\n",
        "  return ChatOpenAI(model=model, temperature=temperature).with_structured_output(\n",
        "    load_output_schema(evaluator),\n",
        "    method='json_schema', strict=True\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "275hVmB1dD74"
      },
      "source": [
        "# Evaluators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCuTVFQOp-z_",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# @title Initialize Components\n",
        "index = get_index()\n",
        "\n",
        "client = Client()\n",
        "\n",
        "#llm = ChatOpenAI(model='qwen/qwen3-8b:free')\n",
        "llm = ChatOpenAI(model='Qwen/Qwen3-8B:featherless-ai')\n",
        "\n",
        "embeddings = HuggingFaceEndpointEmbeddings(model='Qwen/Qwen3-Embedding-8B')\n",
        "\n",
        "vectorstore = PineconeVectorStore(index=index, embedding=embeddings)\n",
        "\n",
        "text_splitter = create_text_splitter()\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "  llm,\n",
        "  retriever=retriever,\n",
        "  combine_docs_chain_kwargs={'prompt': load_chat_prompt('qa_chain')},\n",
        "  return_source_documents=True\n",
        ")\n",
        "\n",
        "create_dataset('FQA.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "c9fc54bb",
        "outputId": "1271e3e6-758c-4071-dadb-73f865ed8768"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(id='46b8f2d3-955d-4652-82d6-b98c9b66f8ac', metadata={'source': '/content/drive/MyDrive/Colab Notebooks/public/RAG_ChatBot/dataset/introduction.txt'}, page_content='Mã số thuế\\t\\n2301025890 - Ngày cấp: 17/04/2018\\nTên đơn vị\\t\\nCÔNG TY TNHH THƯƠNG MẠI VÀ ĐẦU TƯ TỔNG HỢP ANH PHÁT\\nĐịa chỉ theo CQT\\t\\nNR ông Nguyễn Văn Trường, xóm Rừng, khu Bồ Sơn, Phường Võ Cường, Tỉnh Bắc Ninh, Việt Nam\\nĐịa chỉ sau sáp nhập\\t\\nHệ thống tìm thấy 1 kết quả địa chỉ mới liên quan của MST 2301025890:\\n\\n- Địa chỉ 1: NR ông Nguyễn Văn Trường, xóm Rừng, khu Bồ Sơn, Phường Võ Cường, Tỉnh Bắc Ninh, Việt Nam\\n\\n- Căn cứ:\\n\\nPhường Võ Cường: Sắp xếp toàn bộ diện tích tự nhiên, quy mô dân số của các phường Đại Phúc, Phong Khê và Võ Cường thành phường mới có tên gọi là phường Võ Cường.\\n(Thông tin mang tính tham khảo, để có thông tin chính xác vui lòng tra cứu từ website của Cục thuế hoặc Cổng thông tin doanh nghiệp quốc gia trước khi lập/xuất hóa đơn, chứng từ điện tử)\\n\\nTrạng thái\\tNNT đang hoạt động\\nCơ quan thuế quản lý\\tThuế cơ sở 7 tỉnh Bắc Ninh - Mã CQT: 22301\\nPP tính thuế GTGT\\tPhương pháp khấu trừ\\nChương – Khoản\\t855 - 194\\nNgười đại diện theo pháp luật\\t\\nNguyễn Đình Anh'), Document(id='f49d6208-d8fd-473b-b008-62c864840ab6', metadata={'source': '/content/drive/MyDrive/Colab Notebooks/public/RAG_ChatBot/dataset/introduction.txt'}, page_content='Ngành nghề chính\\tBán buôn thiết bị và linh kiện điện tử, viễn thông(Xem danh sách)')]\n"
          ]
        }
      ],
      "source": [
        "chat_history = []\n",
        "query = 'công ty này ở phường nào'\n",
        "response = qa_chain.invoke({'question': query, 'chat_history': chat_history})\n",
        "\n",
        "print(response['source_documents'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vi1zoF_NfyRF",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Correctness\n",
        "def correctness(inputs: dict, outputs: dict, reference_outputs: dict) -> bool:\n",
        "  evaluator = inspect.currentframe().f_code.co_name\n",
        "  grader_llm = create_structured_grader_llm(evaluator=evaluator)\n",
        "  grade = grader_llm.invoke(load_chat_prompt(evaluator).format(\n",
        "    question=inputs['question'],\n",
        "    reference=reference_outputs['answer'],\n",
        "    answer=outputs['answer']\n",
        "  ))\n",
        "  return grade['correct']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Relevance\n",
        "def relevance(inputs: dict, outputs: dict) -> bool:\n",
        "  evaluator = inspect.currentframe().f_code.co_name\n",
        "  grader_llm = create_structured_grader_llm(evaluator=evaluator)\n",
        "  grade = grader_llm.invoke(load_chat_prompt(evaluator).format(\n",
        "    question=inputs['question'],\n",
        "    answer=outputs['answer']\n",
        "  ))\n",
        "  return grade['relevant']"
      ],
      "metadata": {
        "id": "LEHie9jeeQc9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Groundedness\n",
        "def groundedness(inputs: dict, outputs: dict) -> bool:\n",
        "  evaluator = inspect.currentframe().f_code.co_name\n",
        "  grader_llm = create_structured_grader_llm(evaluator=evaluator)\n",
        "  grade = grader_llm.invoke(load_chat_prompt(evaluator).format(\n",
        "    facts='\\n'.join(doc.page_content for doc in outputs[\"documents\"]),\n",
        "    answer=outputs['answer']\n",
        "  ))\n",
        "  return grade['grounded']"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KpkhJOawfBrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Retrieval relevance\n",
        "def retrieval_relevance(inputs: dict, outputs: dict) -> bool:\n",
        "  evaluator = inspect.currentframe().f_code.co_name\n",
        "  grader_llm = create_structured_grader_llm(evaluator=evaluator)\n",
        "  grade = grader_llm.invoke(load_chat_prompt(evaluator).format(\n",
        "    facts='\\n'.join(doc.page_content for doc in outputs[\"documents\"]),\n",
        "    answer=outputs['answer']\n",
        "  ))\n",
        "  return grade['relevant']"
      ],
      "metadata": {
        "id": "50XKGfJpf3ew",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46aanRpmFDYw",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Target for experiment\n",
        "@traceable()\n",
        "def rag_bot(question: str) -> dict:\n",
        "  ai_msg = qa_chain.invoke({'question': question, 'chat_history': []})\n",
        "  return {'answer': ai_msg['answer'], 'documents': ai_msg['source_documents']}\n",
        "\n",
        "def target(inputs: dict) -> dict:\n",
        "  return rag_bot(inputs['question'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iqy-K-Qtwp3R"
      },
      "outputs": [],
      "source": [
        "# @title Experiment\n",
        "def experiment():\n",
        "  experiment_results = client.evaluate(\n",
        "    target,\n",
        "    data='FQA',\n",
        "    evaluators=[correctness, relevance, groundedness, retrieval_relevance],\n",
        "    experiment_prefix='rag-doc-relevance',\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "experiment()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8b36160d4d6a418b839be4e6fd7f8f26",
            "cd9cdcd9c1c54f49b560d2af6358b883",
            "7d8f10ff280343cbba76792c9c80a10a",
            "d17fe824a4304099b5ba6c7411409ee0",
            "3e01d0ba808c4563bd06f1445397b99a",
            "5dd76869a43c474fbd2675efd9c328b2",
            "d822615870a547ae9f80f5009997afcf",
            "c67156aae36040a09bcea4c642e32b75",
            "a909b413bb3a4bd8a3bfba60c71fc786",
            "9ac0f92f38ca4cf985c4e6c9f6d812a2",
            "b2a2b9717f4a4f8f88eae0163b06e36a"
          ]
        },
        "id": "GsYi9z3UeX9N",
        "outputId": "79a2a1bf-d080-4b98-fb55-a6dd6ae2233a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "View the evaluation results for experiment: 'rag-doc-relevance-299079d8' at:\n",
            "https://smith.langchain.com/o/00fa7863-e8c4-446a-9682-0dec08610f9c/datasets/ae8be8f8-25cb-40c3-aeae-5ef8b9c93069/compare?selectedSessions=22118175-c703-43bd-aed6-7f2c943ba064\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b36160d4d6a418b839be4e6fd7f8f26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:langsmith.evaluation._runner:Error running target function: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1757548800000'}, 'provider_name': None}}, 'user_id': 'user_31uNc4Fy7pr9cnTj6uhRqBKDZdV'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/_runner.py\", line 1924, in _forward\n",
            "    fn(*args, langsmith_extra=langsmith_extra)\n",
            "  File \"/tmp/ipython-input-2994525380.py\", line 8, in target\n",
            "    return rag_bot(inputs['question'])\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-2994525380.py\", line 4, in rag_bot\n",
            "    ai_msg = qa_chain.invoke({'question': question, 'chat_history': []})\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\", line 165, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/conversational_retrieval/base.py\", line 175, in _call\n",
            "    answer = self.combine_docs_chain.run(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/_api/deprecation.py\", line 193, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\", line 632, in run\n",
            "    return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/_api/deprecation.py\", line 193, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\", line 410, in __call__\n",
            "    return self.invoke(\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\", line 165, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/combine_documents/base.py\", line 143, in _call\n",
            "    output, extra_return_dict = self.combine_docs(\n",
            "                                ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/combine_documents/stuff.py\", line 263, in combine_docs\n",
            "    return self.llm_chain.predict(callbacks=callbacks, **inputs), {}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/llm.py\", line 325, in predict\n",
            "    return self(kwargs, callbacks=callbacks)[self.output_key]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/_api/deprecation.py\", line 193, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\", line 410, in __call__\n",
            "    return self.invoke(\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\", line 165, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/llm.py\", line 127, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/llm.py\", line 139, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\", line 1023, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\", line 840, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\", line 1089, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\", line 1184, in _generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\", line 1179, in _generate\n",
            "    raw_response = self.client.with_raw_response.create(**payload)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_legacy_response.py\", line 364, in wrapped\n",
            "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
            "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\", line 286, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 1147, in create\n",
            "    return self._post(\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1259, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1047, in request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1757548800000'}, 'provider_name': None}}, 'user_id': 'user_31uNc4Fy7pr9cnTj6uhRqBKDZdV'}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator correctness> on run 80ff1b98-a93a-43a2-95ae-d0ef134ad652: KeyError('answer')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/_runner.py\", line 1620, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
            "    result = self.func(\n",
            "             ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 777, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-296417322.py\", line 8, in correctness\n",
            "    answer=outputs['answer']\n",
            "           ~~~~~~~^^^^^^^^^^\n",
            "KeyError: 'answer'\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator relevance> on run 80ff1b98-a93a-43a2-95ae-d0ef134ad652: KeyError('answer')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/_runner.py\", line 1620, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
            "    result = self.func(\n",
            "             ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 777, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-1562813885.py\", line 7, in relevance\n",
            "    answer=outputs['answer']\n",
            "           ~~~~~~~^^^^^^^^^^\n",
            "KeyError: 'answer'\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator groundedness> on run 80ff1b98-a93a-43a2-95ae-d0ef134ad652: KeyError('documents')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/_runner.py\", line 1620, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
            "    result = self.func(\n",
            "             ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 777, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-1265046449.py\", line 6, in groundedness\n",
            "    facts='\\n'.join(doc.page_content for doc in outputs[\"documents\"]),\n",
            "                                                ~~~~~~~^^^^^^^^^^^^^\n",
            "KeyError: 'documents'\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator retrieval_relevance> on run 80ff1b98-a93a-43a2-95ae-d0ef134ad652: KeyError('documents')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/_runner.py\", line 1620, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
            "    result = self.func(\n",
            "             ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 777, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-2547901753.py\", line 6, in retrieval_relevance\n",
            "    facts='\\n'.join(doc.page_content for doc in outputs[\"documents\"]),\n",
            "                                                ~~~~~~~^^^^^^^^^^^^^\n",
            "KeyError: 'documents'\n",
            "ERROR:langsmith.evaluation._runner:Error running target function: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1757548800000'}, 'provider_name': None}}, 'user_id': 'user_31uNc4Fy7pr9cnTj6uhRqBKDZdV'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/_runner.py\", line 1924, in _forward\n",
            "    fn(*args, langsmith_extra=langsmith_extra)\n",
            "  File \"/tmp/ipython-input-2994525380.py\", line 8, in target\n",
            "    return rag_bot(inputs['question'])\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-2994525380.py\", line 4, in rag_bot\n",
            "    ai_msg = qa_chain.invoke({'question': question, 'chat_history': []})\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\", line 165, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/conversational_retrieval/base.py\", line 175, in _call\n",
            "    answer = self.combine_docs_chain.run(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/_api/deprecation.py\", line 193, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\", line 632, in run\n",
            "    return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/_api/deprecation.py\", line 193, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\", line 410, in __call__\n",
            "    return self.invoke(\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\", line 165, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/combine_documents/base.py\", line 143, in _call\n",
            "    output, extra_return_dict = self.combine_docs(\n",
            "                                ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/combine_documents/stuff.py\", line 263, in combine_docs\n",
            "    return self.llm_chain.predict(callbacks=callbacks, **inputs), {}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/llm.py\", line 325, in predict\n",
            "    return self(kwargs, callbacks=callbacks)[self.output_key]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/_api/deprecation.py\", line 193, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\", line 410, in __call__\n",
            "    return self.invoke(\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\", line 165, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/llm.py\", line 127, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/llm.py\", line 139, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\", line 1023, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\", line 840, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\", line 1089, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\", line 1184, in _generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\", line 1179, in _generate\n",
            "    raw_response = self.client.with_raw_response.create(**payload)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_legacy_response.py\", line 364, in wrapped\n",
            "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
            "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\", line 286, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 1147, in create\n",
            "    return self._post(\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1259, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1047, in request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1757548800000'}, 'provider_name': None}}, 'user_id': 'user_31uNc4Fy7pr9cnTj6uhRqBKDZdV'}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator correctness> on run 9000d508-2c06-4d24-97e2-81dbd0b7e2e4: KeyError('answer')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/_runner.py\", line 1620, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
            "    result = self.func(\n",
            "             ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 777, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-296417322.py\", line 8, in correctness\n",
            "    answer=outputs['answer']\n",
            "           ~~~~~~~^^^^^^^^^^\n",
            "KeyError: 'answer'\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator relevance> on run 9000d508-2c06-4d24-97e2-81dbd0b7e2e4: KeyError('answer')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/_runner.py\", line 1620, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
            "    result = self.func(\n",
            "             ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 777, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-1562813885.py\", line 7, in relevance\n",
            "    answer=outputs['answer']\n",
            "           ~~~~~~~^^^^^^^^^^\n",
            "KeyError: 'answer'\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator groundedness> on run 9000d508-2c06-4d24-97e2-81dbd0b7e2e4: KeyError('documents')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/_runner.py\", line 1620, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
            "    result = self.func(\n",
            "             ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 777, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-1265046449.py\", line 6, in groundedness\n",
            "    facts='\\n'.join(doc.page_content for doc in outputs[\"documents\"]),\n",
            "                                                ~~~~~~~^^^^^^^^^^^^^\n",
            "KeyError: 'documents'\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator retrieval_relevance> on run 9000d508-2c06-4d24-97e2-81dbd0b7e2e4: KeyError('documents')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/_runner.py\", line 1620, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
            "    result = self.func(\n",
            "             ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 777, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-2547901753.py\", line 6, in retrieval_relevance\n",
            "    facts='\\n'.join(doc.page_content for doc in outputs[\"documents\"]),\n",
            "                                                ~~~~~~~^^^^^^^^^^^^^\n",
            "KeyError: 'documents'\n",
            "ERROR:langsmith.evaluation._runner:Error running target function: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1757548800000'}, 'provider_name': None}}, 'user_id': 'user_31uNc4Fy7pr9cnTj6uhRqBKDZdV'}\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/_runner.py\", line 1924, in _forward\n",
            "    fn(*args, langsmith_extra=langsmith_extra)\n",
            "  File \"/tmp/ipython-input-2994525380.py\", line 8, in target\n",
            "    return rag_bot(inputs['question'])\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-2994525380.py\", line 4, in rag_bot\n",
            "    ai_msg = qa_chain.invoke({'question': question, 'chat_history': []})\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\", line 165, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/conversational_retrieval/base.py\", line 175, in _call\n",
            "    answer = self.combine_docs_chain.run(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/_api/deprecation.py\", line 193, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\", line 632, in run\n",
            "    return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/_api/deprecation.py\", line 193, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\", line 410, in __call__\n",
            "    return self.invoke(\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\", line 165, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/combine_documents/base.py\", line 143, in _call\n",
            "    output, extra_return_dict = self.combine_docs(\n",
            "                                ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/combine_documents/stuff.py\", line 263, in combine_docs\n",
            "    return self.llm_chain.predict(callbacks=callbacks, **inputs), {}\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/llm.py\", line 325, in predict\n",
            "    return self(kwargs, callbacks=callbacks)[self.output_key]\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/_api/deprecation.py\", line 193, in warning_emitting_wrapper\n",
            "    return wrapped(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\", line 410, in __call__\n",
            "    return self.invoke(\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/base.py\", line 165, in invoke\n",
            "    self._call(inputs, run_manager=run_manager)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/llm.py\", line 127, in _call\n",
            "    response = self.generate([inputs], run_manager=run_manager)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain/chains/llm.py\", line 139, in generate\n",
            "    return self.llm.generate_prompt(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\", line 1023, in generate_prompt\n",
            "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\", line 840, in generate\n",
            "    self._generate_with_cache(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/chat_models.py\", line 1089, in _generate_with_cache\n",
            "    result = self._generate(\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\", line 1184, in _generate\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langchain_openai/chat_models/base.py\", line 1179, in _generate\n",
            "    raw_response = self.client.with_raw_response.create(**payload)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_legacy_response.py\", line 364, in wrapped\n",
            "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
            "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\", line 286, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\", line 1147, in create\n",
            "    return self._post(\n",
            "           ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1259, in post\n",
            "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
            "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\", line 1047, in request\n",
            "    raise self._make_status_error_from_response(err.response) from None\n",
            "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit exceeded: free-models-per-day. Add 10 credits to unlock 1000 free model requests per day', 'code': 429, 'metadata': {'headers': {'X-RateLimit-Limit': '50', 'X-RateLimit-Remaining': '0', 'X-RateLimit-Reset': '1757548800000'}, 'provider_name': None}}, 'user_id': 'user_31uNc4Fy7pr9cnTj6uhRqBKDZdV'}\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator correctness> on run 9594651e-e6eb-4fb4-b00c-cff26ad00d45: KeyError('answer')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/_runner.py\", line 1620, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
            "    result = self.func(\n",
            "             ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 777, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-296417322.py\", line 8, in correctness\n",
            "    answer=outputs['answer']\n",
            "           ~~~~~~~^^^^^^^^^^\n",
            "KeyError: 'answer'\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator relevance> on run 9594651e-e6eb-4fb4-b00c-cff26ad00d45: KeyError('answer')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/_runner.py\", line 1620, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
            "    result = self.func(\n",
            "             ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 777, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-1562813885.py\", line 7, in relevance\n",
            "    answer=outputs['answer']\n",
            "           ~~~~~~~^^^^^^^^^^\n",
            "KeyError: 'answer'\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator groundedness> on run 9594651e-e6eb-4fb4-b00c-cff26ad00d45: KeyError('documents')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/_runner.py\", line 1620, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
            "    result = self.func(\n",
            "             ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 777, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-1265046449.py\", line 6, in groundedness\n",
            "    facts='\\n'.join(doc.page_content for doc in outputs[\"documents\"]),\n",
            "                                                ~~~~~~~^^^^^^^^^^^^^\n",
            "KeyError: 'documents'\n",
            "ERROR:langsmith.evaluation._runner:Error running evaluator <DynamicRunEvaluator retrieval_relevance> on run 9594651e-e6eb-4fb4-b00c-cff26ad00d45: KeyError('documents')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/_runner.py\", line 1620, in _run_evaluators\n",
            "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 351, in evaluate_run\n",
            "    result = self.func(\n",
            "             ^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/langsmith/evaluation/evaluator.py\", line 777, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-2547901753.py\", line 6, in retrieval_relevance\n",
            "    facts='\\n'.join(doc.page_content for doc in outputs[\"documents\"]),\n",
            "                                                ~~~~~~~^^^^^^^^^^^^^\n",
            "KeyError: 'documents'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(experiment_results.to_pandas().to_markdown())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YgM_RtXZXIn",
        "outputId": "77d96998-128e-428c-97c5-3e69b90dc63b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|    | inputs.question                                                      | outputs.answer                                                                                                                                                                                                                                                 | outputs.documents                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | error   | reference.answer                                                                                                                                                | feedback.correctness   | feedback.relevance   | feedback.groundedness   | feedback.retrieval_relevance   |   execution_time | example_id                           | id                                   |\n",
            "|---:|:---------------------------------------------------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:--------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------|:-----------------------|:---------------------|:------------------------|:-------------------------------|-----------------:|:-------------------------------------|:-------------------------------------|\n",
            "|  0 | What are the types of biases that can arise with few-shot prompting? | I don't know. The provided context contains information about a company's tax details and address changes but does not cover topics related to AI biases or few-shot prompting. Please provide relevant sources or clarify your question.                      | [Document(id='46b8f2d3-955d-4652-82d6-b98c9b66f8ac', metadata={'source': '/content/drive/MyDrive/Colab Notebooks/public/RAG_ChatBot/dataset/introduction.txt'}, page_content='Mã số thuế\\t\\n2301025890 - Ngày cấp: 17/04/2018\\nTên đơn vị\\t\\nCÔNG TY TNHH THƯƠNG MẠI VÀ ĐẦU TƯ TỔNG HỢP ANH PHÁT\\nĐịa chỉ theo CQT\\t\\nNR ông Nguyễn Văn Trường, xóm Rừng, khu Bồ Sơn, Phường Võ Cường, Tỉnh Bắc Ninh, Việt Nam\\nĐịa chỉ sau sáp nhập\\t\\nHệ thống tìm thấy 1 kết quả địa chỉ mới liên quan của MST 2301025890:\\n\\n- Địa chỉ 1: NR ông Nguyễn Văn Trường, xóm Rừng, khu Bồ Sơn, Phường Võ Cường, Tỉnh Bắc Ninh, Việt Nam\\n\\n- Căn cứ:\\n\\nPhường Võ Cường: Sắp xếp toàn bộ diện tích tự nhiên, quy mô dân số của các phường Đại Phúc, Phong Khê và Võ Cường thành phường mới có tên gọi là phường Võ Cường.\\n(Thông tin mang tính tham khảo, để có thông tin chính xác vui lòng tra cứu từ website của Cục thuế hoặc Cổng thông tin doanh nghiệp quốc gia trước khi lập/xuất hóa đơn, chứng từ điện tử)\\n\\nTrạng thái\\tNNT đang hoạt động\\nCơ quan thuế quản lý\\tThuế cơ sở 7 tỉnh Bắc Ninh - Mã CQT: 22301\\nPP tính thuế GTGT\\tPhương pháp khấu trừ\\nChương – Khoản\\t855 - 194\\nNgười đại diện theo pháp luật\\t\\nNguyễn Đình Anh'), Document(id='f49d6208-d8fd-473b-b008-62c864840ab6', metadata={'source': '/content/drive/MyDrive/Colab Notebooks/public/RAG_ChatBot/dataset/introduction.txt'}, page_content='Ngành nghề chính\\tBán buôn thiết bị và linh kiện điện tử, viễn thông(Xem danh sách)')] |         | The biases that can arise with few-shot prompting include (1) Majority label bias, (2) Recency bias, and (3) Common token bias.                                 | False                  | False                | True                    | False                          |          10.958  | bf8463d8-79f1-401a-bc8b-716bda9ceaf8 | 725dd104-503b-42fa-b425-30157fb88e99 |\n",
            "|  1 | What are five types of adversarial attacks?                          | The provided documents contain information about a company's tax details and do not mention adversarial attacks or related topics. Therefore, I cannot answer the question based on the given sources.                                                         | [Document(id='46b8f2d3-955d-4652-82d6-b98c9b66f8ac', metadata={'source': '/content/drive/MyDrive/Colab Notebooks/public/RAG_ChatBot/dataset/introduction.txt'}, page_content='Mã số thuế\\t\\n2301025890 - Ngày cấp: 17/04/2018\\nTên đơn vị\\t\\nCÔNG TY TNHH THƯƠNG MẠI VÀ ĐẦU TƯ TỔNG HỢP ANH PHÁT\\nĐịa chỉ theo CQT\\t\\nNR ông Nguyễn Văn Trường, xóm Rừng, khu Bồ Sơn, Phường Võ Cường, Tỉnh Bắc Ninh, Việt Nam\\nĐịa chỉ sau sáp nhập\\t\\nHệ thống tìm thấy 1 kết quả địa chỉ mới liên quan của MST 2301025890:\\n\\n- Địa chỉ 1: NR ông Nguyễn Văn Trường, xóm Rừng, khu Bồ Sơn, Phường Võ Cường, Tỉnh Bắc Ninh, Việt Nam\\n\\n- Căn cứ:\\n\\nPhường Võ Cường: Sắp xếp toàn bộ diện tích tự nhiên, quy mô dân số của các phường Đại Phúc, Phong Khê và Võ Cường thành phường mới có tên gọi là phường Võ Cường.\\n(Thông tin mang tính tham khảo, để có thông tin chính xác vui lòng tra cứu từ website của Cục thuế hoặc Cổng thông tin doanh nghiệp quốc gia trước khi lập/xuất hóa đơn, chứng từ điện tử)\\n\\nTrạng thái\\tNNT đang hoạt động\\nCơ quan thuế quản lý\\tThuế cơ sở 7 tỉnh Bắc Ninh - Mã CQT: 22301\\nPP tính thuế GTGT\\tPhương pháp khấu trừ\\nChương – Khoản\\t855 - 194\\nNgười đại diện theo pháp luật\\t\\nNguyễn Đình Anh'), Document(id='f49d6208-d8fd-473b-b008-62c864840ab6', metadata={'source': '/content/drive/MyDrive/Colab Notebooks/public/RAG_ChatBot/dataset/introduction.txt'}, page_content='Ngành nghề chính\\tBán buôn thiết bị và linh kiện điện tử, viễn thông(Xem danh sách)')] |         | Five types of adversarial attacks are (1) Token manipulation, (2) Gradient based attack, (3) Jailbreak prompting, (4) Human red-teaming, (5) Model red-teaming. | False                  | False                | True                    | False                          |          13.2219 | d012d491-07a0-4cfb-9ac8-d95aeb785176 | 0c63edf4-a6a6-475f-bf1d-1661d373aeb5 |\n",
            "|  2 | How does the ReAct agent use self-reflection?                        | The provided documents contain no information about the ReAct agent or its use of self-reflection. They detail a company's tax registration and legal information in Vietnam. Please refer to additional sources for details on the ReAct agent's methodology. | [Document(id='46b8f2d3-955d-4652-82d6-b98c9b66f8ac', metadata={'source': '/content/drive/MyDrive/Colab Notebooks/public/RAG_ChatBot/dataset/introduction.txt'}, page_content='Mã số thuế\\t\\n2301025890 - Ngày cấp: 17/04/2018\\nTên đơn vị\\t\\nCÔNG TY TNHH THƯƠNG MẠI VÀ ĐẦU TƯ TỔNG HỢP ANH PHÁT\\nĐịa chỉ theo CQT\\t\\nNR ông Nguyễn Văn Trường, xóm Rừng, khu Bồ Sơn, Phường Võ Cường, Tỉnh Bắc Ninh, Việt Nam\\nĐịa chỉ sau sáp nhập\\t\\nHệ thống tìm thấy 1 kết quả địa chỉ mới liên quan của MST 2301025890:\\n\\n- Địa chỉ 1: NR ông Nguyễn Văn Trường, xóm Rừng, khu Bồ Sơn, Phường Võ Cường, Tỉnh Bắc Ninh, Việt Nam\\n\\n- Căn cứ:\\n\\nPhường Võ Cường: Sắp xếp toàn bộ diện tích tự nhiên, quy mô dân số của các phường Đại Phúc, Phong Khê và Võ Cường thành phường mới có tên gọi là phường Võ Cường.\\n(Thông tin mang tính tham khảo, để có thông tin chính xác vui lòng tra cứu từ website của Cục thuế hoặc Cổng thông tin doanh nghiệp quốc gia trước khi lập/xuất hóa đơn, chứng từ điện tử)\\n\\nTrạng thái\\tNNT đang hoạt động\\nCơ quan thuế quản lý\\tThuế cơ sở 7 tỉnh Bắc Ninh - Mã CQT: 22301\\nPP tính thuế GTGT\\tPhương pháp khấu trừ\\nChương – Khoản\\t855 - 194\\nNgười đại diện theo pháp luật\\t\\nNguyễn Đình Anh'), Document(id='f49d6208-d8fd-473b-b008-62c864840ab6', metadata={'source': '/content/drive/MyDrive/Colab Notebooks/public/RAG_ChatBot/dataset/introduction.txt'}, page_content='Ngành nghề chính\\tBán buôn thiết bị và linh kiện điện tử, viễn thông(Xem danh sách)')] |         | ReAct integrates reasoning and acting, performing actions - such tools like Wikipedia search API - and then observing / reasoning about the tool outputs.       | False                  | False                | True                    | True                           |          10.5362 | e81bee28-69f5-4c43-8c95-7b2f1474e93b | bb4dab41-f400-40ec-9ac4-9830cb606dfa |\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1UvmP-pkUnlIOrt37odrdShOdS3-RVI7_",
      "authorship_tag": "ABX9TyPCxN7UAn4ml1xYsz5fO7V9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8b36160d4d6a418b839be4e6fd7f8f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd9cdcd9c1c54f49b560d2af6358b883",
              "IPY_MODEL_7d8f10ff280343cbba76792c9c80a10a",
              "IPY_MODEL_d17fe824a4304099b5ba6c7411409ee0"
            ],
            "layout": "IPY_MODEL_3e01d0ba808c4563bd06f1445397b99a"
          }
        },
        "cd9cdcd9c1c54f49b560d2af6358b883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dd76869a43c474fbd2675efd9c328b2",
            "placeholder": "​",
            "style": "IPY_MODEL_d822615870a547ae9f80f5009997afcf",
            "value": ""
          }
        },
        "7d8f10ff280343cbba76792c9c80a10a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c67156aae36040a09bcea4c642e32b75",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a909b413bb3a4bd8a3bfba60c71fc786",
            "value": 1
          }
        },
        "d17fe824a4304099b5ba6c7411409ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ac0f92f38ca4cf985c4e6c9f6d812a2",
            "placeholder": "​",
            "style": "IPY_MODEL_b2a2b9717f4a4f8f88eae0163b06e36a",
            "value": " 3/? [00:09&lt;00:00,  3.15s/it]"
          }
        },
        "3e01d0ba808c4563bd06f1445397b99a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dd76869a43c474fbd2675efd9c328b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d822615870a547ae9f80f5009997afcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c67156aae36040a09bcea4c642e32b75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a909b413bb3a4bd8a3bfba60c71fc786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ac0f92f38ca4cf985c4e6c9f6d812a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2a2b9717f4a4f8f88eae0163b06e36a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}