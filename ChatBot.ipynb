{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lehuong240823/rag-company-knowledge-consultant-chatbot/blob/main/ChatBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20GrbDZgi1mj"
      },
      "source": [
        "# Get Started"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "collapsed": true,
        "id": "QJQ8OZPL5war"
      },
      "outputs": [],
      "source": [
        "# @title Install Libraries\n",
        "!pip -q install pinecone\n",
        "!pip -q install langchain_community\n",
        "!pip -q install langchain_openai\n",
        "!pip -q install langchain_pinecone\n",
        "!pip -q install langchain-huggingface\n",
        "!pip -q install langsmith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRwdJs_82XKX",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Import Libraries\n",
        "import os, yaml, inspect, json, datetime, pytz, hashlib\n",
        "from os.path import join\n",
        "from google.colab import userdata\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEndpointEmbeddings\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
        "from langchain_pinecone.vectorstores import PineconeVectorStore\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from langsmith import Client, traceable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SC-bUdQ15Aq"
      },
      "outputs": [],
      "source": [
        "# @title Set Environment Variables\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = userdata.get('HF_TOKEN')\n",
        "os.environ['LANGSMITH_API_KEY'] = userdata.get('LANGSMITH_API_KEY')\n",
        "os.environ['LANGSMITH_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGSMITH_PROJECT'] = userdata.get('PINECONE_INDEX_NAME')\n",
        "os.environ['LANGSMITH_TRACING'] = 'true'\n",
        "os.environ['OPENAI_API_BASE'] = 'https://router.huggingface.co/v1' #'https://openrouter.ai/api/v1'\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('HF_TOKEN') #userdata.get('OPENROUTER_API_KEY')\n",
        "os.environ['PINECONE_API_KEY'] = userdata.get('PINECONE_API_KEY')\n",
        "os.environ['PINECONE_INDEX_NAME'] = userdata.get('PINECONE_INDEX_NAME')\n",
        "os.environ['GITHUB_PERSONAL_ACCESS_TOKEN'] = userdata.get('GITHUB_PERSONAL_ACCESS_TOKEN')\n",
        "root_path =  userdata.get('ROOT_PATH')\n",
        "embedding_path = join(root_path, 'embedding_data')\n",
        "reference_path = join(root_path, 'reference_data')\n",
        "evaluators_path = join(root_path, 'evaluators')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJUrQT_gZ5Z3"
      },
      "source": [
        "# Method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EwutUmxfMdsj"
      },
      "outputs": [],
      "source": [
        "# @title Get Pinecone Index\n",
        "def get_index(index_name=os.environ['PINECONE_INDEX_NAME']):\n",
        "  pc = Pinecone()\n",
        "  if not pc.has_index(index_name):\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=4096,\n",
        "        metric='cosine',\n",
        "        spec=ServerlessSpec(\n",
        "            cloud='aws',\n",
        "            region='us-east-1'\n",
        "        )\n",
        "    )\n",
        "\n",
        "  return pc.Index(index_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EraOySvvAa4p"
      },
      "outputs": [],
      "source": [
        "# @title Create Text Splitter\n",
        "def create_text_splitter(chunk_size=1000, chunk_overlap=0):\n",
        "  return CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RfuW_ILI5vx"
      },
      "outputs": [],
      "source": [
        "def get_timestamp():\n",
        "  vietnam_timezone = pytz.timezone('Asia/Ho_Chi_Minh')\n",
        "  vietnam_time = datetime.datetime.now(vietnam_timezone)\n",
        "  return vietnam_time.isoformat()\n",
        "\n",
        "def hash(text):\n",
        "  '''MD% hash for track change'''\n",
        "  return hashlib.md5(text.encode('utf-8')).hexdigest()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTe9PQ6I8fV4"
      },
      "outputs": [],
      "source": [
        "# @title Add Documents to Vector Store\n",
        "def Loader(file):\n",
        "  if file.endswith('.csv'):\n",
        "    loader = CSVLoader(file)\n",
        "  elif file.endswith('.txt'):\n",
        "    loader = TextLoader(file)\n",
        "  return loader\n",
        "\n",
        "def add_documents(path, ids):\n",
        "  loader = Loader(path)\n",
        "  documents = loader.load()\n",
        "  for each in documents:\n",
        "    each.metadata['timestamp'] = get_timestamp()\n",
        "  print([each.metadata for each in documents])\n",
        "  print(f'Loaded {len(documents)} document(s) from {path}')\n",
        "  docs = text_splitter.split_documents(documents)\n",
        "  #vectorstore.add_documents(docs, ids=[f'{ids}_{str(i)}' for i in range(0, len(docs))])\n",
        "  print(f'Added {len(docs)} text chunk(s) to vector store.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zkQi2ymS42J"
      },
      "outputs": [],
      "source": [
        "# @title Add All Ref Data to Vectorstore\n",
        "for root, dirs, files in os.walk(reference_path):\n",
        "  for name in files:\n",
        "    path = join(root, name)\n",
        "    add_documents(path, name[:-4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EU2XDErYCfLH"
      },
      "outputs": [],
      "source": [
        "# @title Add Texts to Vector Store\n",
        "def add_texts(text):\n",
        "  texts = text_splitter.split_text(text)\n",
        "  vectorstore.add_texts(texts)\n",
        "  print(f'Added {len(texts)} text chunks to vector store.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "eba05b0e"
      },
      "outputs": [],
      "source": [
        "# @title Get Evaluator Path\n",
        "def get_evaluator_path(evaluator_name):\n",
        "  return f'{evaluators_path}/{evaluator_name}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "fdc50271"
      },
      "outputs": [],
      "source": [
        "# @title Load Output Schema\n",
        "def load_output_schema(evaluator_name):\n",
        "  file_path = f'{get_evaluator_path(evaluator_name)}/output_schema.yaml'\n",
        "  with open(file_path, 'r') as f:\n",
        "    return yaml.safe_load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cc4dc6ba"
      },
      "outputs": [],
      "source": [
        "# @title Load Chat Prompt\n",
        "def load_chat_prompt(evaluator):\n",
        "  file_path = f'{get_evaluator_path(evaluator)}/prompt.yaml'\n",
        "  with open(file_path, 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "  role_map = {'system': SystemMessagePromptTemplate, 'user': HumanMessagePromptTemplate, 'ai': AIMessagePromptTemplate}\n",
        "\n",
        "  messages = []\n",
        "  for msg_config in config['messages']:\n",
        "    messages.append(role_map[msg_config['role']].from_template(msg_config['template']))\n",
        "  #messages = [role_map[m['role']].from_template(m['template']) for m in cfg['messages']]\n",
        "\n",
        "  return ChatPromptTemplate.from_messages(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "SBX_Qx0pMcuq"
      },
      "outputs": [],
      "source": [
        "# @title Create LangSmith Dataset\n",
        "def create_dataset(file_name, dataset_name=None, provider='langsmith'):\n",
        "  #Load json file only\n",
        "  dataset_name = file_name[:-5] if dataset_name is None else dataset_name\n",
        "  with open(join(embedding_path, provider, file_name)) as f:\n",
        "    if not client.has_dataset(dataset_name=dataset_name):\n",
        "      return client.create_dataset(dataset_name=dataset_name)\n",
        "      client.create_examples(\n",
        "        dataset_id=dataset.id,\n",
        "        examples=json.load(f)\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMr6Xf8SnsEt"
      },
      "outputs": [],
      "source": [
        "# @title Create Structured Grader LLM\n",
        "def create_structured_grader_llm(model='qwen/qwen3-8b:free', temperature=0, evaluator=None):\n",
        "  return ChatOpenAI(model=model, temperature=temperature).with_structured_output(\n",
        "    load_output_schema(evaluator),\n",
        "    method='json_schema', strict=True\n",
        "  )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "275hVmB1dD74"
      },
      "source": [
        "# Evaluators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KCuTVFQOp-z_",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Initialize Components\n",
        "index = get_index()\n",
        "\n",
        "client = Client()\n",
        "\n",
        "#llm = ChatOpenAI(model='qwen/qwen3-8b:free')\n",
        "llm = ChatOpenAI(model='Qwen/Qwen3-8B:featherless-ai')\n",
        "\n",
        "embeddings = HuggingFaceEndpointEmbeddings(model='Qwen/Qwen3-Embedding-8B')\n",
        "\n",
        "vectorstore = PineconeVectorStore(index=index, embedding=embeddings)\n",
        "\n",
        "text_splitter = create_text_splitter()\n",
        "\n",
        "retriever = vectorstore.as_retriever(k=2)\n",
        "\n",
        "qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "  llm,\n",
        "  retriever=retriever,\n",
        "  combine_docs_chain_kwargs={'prompt': load_chat_prompt('qa_chain')},\n",
        "  return_source_documents=True\n",
        ")\n",
        "\n",
        "#create_dataset('fqa.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "c9fc54bb"
      },
      "outputs": [],
      "source": [
        "chat_history = []\n",
        "query = 'công ty này ở phường nào'\n",
        "response = qa_chain.invoke({'question': query, 'chat_history': chat_history})\n",
        "\n",
        "print(response['source_documents'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "vi1zoF_NfyRF"
      },
      "outputs": [],
      "source": [
        "# @title Correctness\n",
        "def correctness(inputs: dict, outputs: dict, reference_outputs: dict) -> bool:\n",
        "  evaluator = inspect.currentframe().f_code.co_name\n",
        "  grader_llm = create_structured_grader_llm(evaluator=evaluator)\n",
        "  grade = grader_llm.invoke(load_chat_prompt(evaluator).format(\n",
        "    question=inputs['question'],\n",
        "    reference=reference_outputs['answer'],\n",
        "    answer=outputs['answer']\n",
        "  ))\n",
        "  return grade['correct']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LEHie9jeeQc9"
      },
      "outputs": [],
      "source": [
        "# @title Relevance\n",
        "def relevance(inputs: dict, outputs: dict) -> bool:\n",
        "  evaluator = inspect.currentframe().f_code.co_name\n",
        "  grader_llm = create_structured_grader_llm(evaluator=evaluator)\n",
        "  grade = grader_llm.invoke(load_chat_prompt(evaluator).format(\n",
        "    question=inputs['question'],\n",
        "    answer=outputs['answer']\n",
        "  ))\n",
        "  return grade['relevant']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KpkhJOawfBrC"
      },
      "outputs": [],
      "source": [
        "# @title Groundedness\n",
        "def groundedness(inputs: dict, outputs: dict) -> bool:\n",
        "  evaluator = inspect.currentframe().f_code.co_name\n",
        "  grader_llm = create_structured_grader_llm(evaluator=evaluator)\n",
        "  grade = grader_llm.invoke(load_chat_prompt(evaluator).format(\n",
        "    facts='\\n'.join(doc.page_content for doc in outputs[\"documents\"]),\n",
        "    answer=outputs['answer']\n",
        "  ))\n",
        "  return grade['grounded']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "50XKGfJpf3ew"
      },
      "outputs": [],
      "source": [
        "# @title Retrieval relevance\n",
        "def retrieval_relevance(inputs: dict, outputs: dict) -> bool:\n",
        "  evaluator = inspect.currentframe().f_code.co_name\n",
        "  grader_llm = create_structured_grader_llm(evaluator=evaluator)\n",
        "  grade = grader_llm.invoke(load_chat_prompt(evaluator).format(\n",
        "    facts='\\n'.join(doc.page_content for doc in outputs[\"documents\"]),\n",
        "    answer=outputs['answer']\n",
        "  ))\n",
        "  return grade['relevant']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46aanRpmFDYw"
      },
      "outputs": [],
      "source": [
        "# @title Target for Experiment\n",
        "@traceable()\n",
        "def rag_bot(question: str) -> dict:\n",
        "  ai_msg = qa_chain.invoke({'question': question, 'chat_history': []})\n",
        "  return {'answer': ai_msg['answer'], 'documents': ai_msg['source_documents']}\n",
        "\n",
        "def target(inputs: dict) -> dict:\n",
        "  return rag_bot(inputs['question'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iqy-K-Qtwp3R"
      },
      "outputs": [],
      "source": [
        "# @title Experiment\n",
        "def experiment():\n",
        "  experiment_results = client.evaluate(\n",
        "    target,\n",
        "    data='fqa',\n",
        "    evaluators=[correctness, relevance, groundedness, retrieval_relevance],\n",
        "    experiment_prefix='rag-doc-relevance',\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsYi9z3UeX9N",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "experiment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YgM_RtXZXIn"
      },
      "outputs": [],
      "source": [
        "print(experiment_results.to_pandas().to_markdown())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1UvmP-pkUnlIOrt37odrdShOdS3-RVI7_",
      "authorship_tag": "ABX9TyOnBrJ9lpjn2x70oF8W8+/r",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}